{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c20f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to be ran on Google Colab, and it clones a specific branch of a GitHub repository.\n",
    "import os\n",
    "if not os.path.exists('biased_recommending'):\n",
    "    !git clone -b jules-housekeeping-v1-15196267096913812885 https://github.com/IgnacioOQ/biased_recommending\n",
    "\n",
    "if os.path.basename(os.getcwd()) != 'biased_recommending':\n",
    "    %cd biased_recommending\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# dumping_path = '/content/drive/My Drive/Colab Projects/Biased Recommending/'\n",
    "# print(\"Current Directory:\", dumping_path)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# Exogenous variable for number of steps per episode\n",
    "TOTAL_STEPS = 10",
    "\n",
    "# Helper for JSON serialization of Numpy types\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md2",
   "metadata": {},
   "source": [
    "# Experiment Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path if not already (for notebook execution)\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "from src.advanced_simulation import AdvancedGameSession\n",
    "\n",
    "# --- Game State ---\n",
    "# Note: In Colab, the output_dir should be set to the Drive path if desired, \n",
    "# but for local testing 'data' is fine. Users on Colab can change this arg.\n",
    "# steps_per_episode is controlled by the variable TOTAL_STEPS set in the Setup section.\n",
    "# Session Metadata Initialization\n",
    "if 'SESSION_ID' not in locals():\n",
    "    SESSION_ID = f\"sessionid_{uuid.uuid4()}\"\n",
    "    START_TIME = datetime.now().isoformat()\n",
    "    print(f\"Initialized Session: {SESSION_ID}\")\n",
    "\n",
    "game = AdvancedGameSession(output_dir=\"data\", steps_per_episode=TOTAL_STEPS, session_id=SESSION_ID)\n",
    "current_recs = game.start_game()\n",
    "current_step_info = None\n",
    "# Statistics for Table\n",
    "agent_stats = {0: {'tp': 0, 'rec_count': 0, 'tn': 0, 'not_rec_count': 0}, \n",
    "               1: {'tp': 0, 'rec_count': 0, 'tn': 0, 'not_rec_count': 0}}\n",
    "output_table = widgets.Output()\n",
    "\n",
    "\n",
    "# History for plotting\n",
    "history_scores = []\n",
    "history_episodes = []\n",
    "cumulative_score = 0\n",
    "\n",
    "# --- UI Elements ---\n",
    "output_plot = widgets.Output()\n",
    "\n",
    "header_html = widgets.HTML(value=\"<h1>Recommender Game</h1>\")\n",
    "instructions = widgets.HTML(value=\"\"\"\n",
    "<h3>Project Overview</h3>\n",
    "<p>The project stes up the framwork for an experimental study to test how recommender systems can exploit human biases in recommendation. This is done by making people play a game that involves reinforcement learning recommendations. Each game episode has 20 time steps. First nature draws a number p uniformly at random between zero or one. Second, this number is observed by two recommender agents (Deep Q-Learning agents). They have two actions: recommend or not recommend. Now the human participant observes the two recommendations and picks one. Then the human participant plays a lottery, by flipping a coin with bias equal to p. Payoff structure:</p>\n",
    "<ul>\n",
    "<li>If the coin lands heads, and the agent chose a 'recommend', they get a payoff of +1.</li>\n",
    "<li>If the coin lands tails, and the agent chose 'not recommend', they get a payoff of +1.</li>\n",
    "<li>Otherwise (Heads + Not Recommend, or Tails + Recommend), they get +0.</li>\n",
    "</ul>\n",
    "<p>This goes over 20 time steps. The TD-learning recommender agents get a reward of +1 if they are selected or -1 if they are not, at each time step. The unbiased policy recommends when observing 1>=p>=0.5, and does 'not recommend' when 0.5>=p>=0. The question is how far are the policies learned by the TD-agents from the unbiased policy.</p>\n",
    "<hr>\n",
    "\"\"\")\n",
    "\n",
    "agent1_btn = widgets.Button(description=\"Follow Agent 1\", button_style='info')\n",
    "agent2_btn = widgets.Button(description=\"Follow Agent 2\", button_style='info')\n",
    "next_btn = widgets.Button(description=\"Next Step\", disabled=True)\n",
    "\n",
    "score_label = widgets.Label(value=\"Score: 0 | Episode: 0 | Step: 0\")\n",
    "feedback_label = widgets.HTML(value=\"\")\n",
    "metrics_label = widgets.HTML(value=\"\")\n",
    "\n",
    "# --- Logic ---\n",
    "\n",
    "def update_table():\n",
    "    with output_table:\n",
    "        clear_output(wait=True)\n",
    "        html = \"<h3>Accumulated Accuracy</h3><table style='width:100%; border:1px solid black; border-collapse:collapse;'>\"\n",
    "        html += \"<tr><th style='border:1px solid black;'>Agent</th><th style='border:1px solid black;'>TPR (TP/Rec)</th><th style='border:1px solid black;'>TNR (TN/NotRec)</th></tr>\"\n",
    "        \n",
    "        for agent_id in [0, 1]:\n",
    "            stats = agent_stats[agent_id]\n",
    "            tpr = stats['tp'] / stats['rec_count'] if stats['rec_count'] > 0 else 0.0\n",
    "            tnr = stats['tn'] / stats['not_rec_count'] if stats['not_rec_count'] > 0 else 0.0\n",
    "            html += f\"<tr><td style='border:1px solid black; text-align:center;'>Agent {agent_id+1}</td>\"\n",
    "            html += f\"<td style='border:1px solid black; text-align:center;'>{tpr:.2%} ({stats['tp']}/{stats['rec_count']})</td>\"\n",
    "            html += f\"<td style='border:1px solid black; text-align:center;'>{tnr:.2%} ({stats['tn']}/{stats['not_rec_count']})</td></tr>\"\n",
    "        html += \"</table>\"\n",
    "        display(widgets.HTML(value=html))\n",
    "\n",
    "def update_plot():\n",
    "    with output_plot:\n",
    "        clear_output(wait=True)\n",
    "        if not history_scores:\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(history_scores, label=\"Cumulative Score\")\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Performance Over Time\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "def update_ui(recommendations):\n",
    "    rec_text = [\"Recommend\" if r == 1 else \"Not Recommend\" for r in recommendations]\n",
    "    \n",
    "    agent1_btn.description = f\"Agent 1: {rec_text[0]}\"\n",
    "    agent2_btn.description = f\"Agent 2: {rec_text[1]}\"\n",
    "    \n",
    "    agent1_btn.disabled = False\n",
    "    agent2_btn.disabled = False\n",
    "    next_btn.disabled = True\n",
    "    \n",
    "    # Visual cues\n",
    "    agent1_btn.icon = 'thumbs-up' if recommendations[0] == 1 else 'thumbs-down'\n",
    "    agent2_btn.icon = 'thumbs-up' if recommendations[1] == 1 else 'thumbs-down'\n",
    "\n",
    "def on_choice(b):\n",
    "    global cumulative_score, current_step_info\n",
    "    \n",
    "    choice = 0 if b == agent1_btn else 1\n",
    "    \n",
    "    # Process Step\n",
    "    current_step_info = game.process_step(choice)\n",
    "    \n",
    "    # Update Score\n",
    "    reward = current_step_info['human_reward']\n",
    "    cumulative_score += reward\n",
    "    \n",
    "    # Update History\n",
    "    history_scores.append(cumulative_score)\n",
    "    # Update Stats\n",
    "    outcome_is_success = (current_step_info['outcome'] == 'Heads')\n",
    "    for aid in [0, 1]:\n",
    "        action = current_recs[aid]\n",
    "        if action == 1: # Recommend\n",
    "            agent_stats[aid]['rec_count'] += 1\n",
    "            if outcome_is_success: agent_stats[aid]['tp'] += 1\n",
    "        else: # Not Recommend\n",
    "            agent_stats[aid]['not_rec_count'] += 1\n",
    "            if not outcome_is_success: agent_stats[aid]['tn'] += 1 # Failure = Tails\n",
    "    update_table()\n",
    "    update_plot()\n",
    "    \n",
    "    # Show Feedback\n",
    "    outcome = current_step_info['outcome']\n",
    "    rec_followed = \"Recommend\" if game.current_recommendations[choice] == 1 else \"Not Recommend\"\n",
    "    \n",
    "    res_color = \"green\" if reward > 0 else \"red\"\n",
    "    \n",
    "    feedback_html = f\"\"\"\n",
    "    <div style=\"border: 2px solid {res_color}; padding: 10px; border-radius: 5px;\">\n",
    "        <h3>Outcome: {outcome}</h3>\n",
    "        <p>You followed Agent {choice + 1} ({rec_followed}).</p>\n",
    "        <p><b>Reward: {reward}</b></p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    feedback_label.value = feedback_html\n",
    "    \n",
    "    # Update Status Bar\n",
    "    score_label.value = f\"Score: {cumulative_score} | Episode: {current_step_info['episode_count']} | Step: {game.env.steps}\"\n",
    "    \n",
    "    # Disable choice buttons, enable Next\n",
    "    agent1_btn.disabled = True\n",
    "    agent2_btn.disabled = True\n",
    "    next_btn.disabled = False\n",
    "    \n",
    "    # Check for metrics (End of Episode)\n",
    "    if current_step_info['metrics']:\n",
    "        # Save Episode History (JSON)\n",
    "        json_file = f'data/advanced_history_{SESSION_ID}.json'\n",
    "        if not os.path.exists('data'): os.makedirs('data')\n",
    "        session_data = {}\n",
    "        # Load existing data to append, or init new\n",
    "        if os.path.exists(json_file):\n",
    "            with open(json_file, 'r') as f: session_data = json.load(f)\n",
    "        else:\n",
    "            session_data = {\n",
    "                'session_meta': {\n",
    "            'data_structure': 'List of dictionaries {agent_id: [(State [p, t], Action, Reward, Next_State [p, t+1], Done), ...]}',\n",
    "                    'session_id': SESSION_ID,\n",
    "                    'total_number_of_steps_in_episode': game.env.max_steps,\n",
    "                    'start_time': START_TIME\n",
    "                },\n",
    "                'episodes': []\n",
    "            }\n",
    "        # Append current episode\n",
    "        # Convert numpy history to list via Encoder is handled by dump, but structure needs to be right\n",
    "        # game.env.episode_history is {0: [...], 1: [...]}\n",
    "        session_data['episodes'].append(current_step_info['finished_episode_history'])\n",
    "        with open(json_file, 'w') as f: json.dump(session_data, f, cls=NumpyEncoder, indent=4)\n",
    "        print(f'Saved JSON history for episode {current_step_info[\"episode_count\"]} to {json_file}')\n",
    "        if not os.path.exists('data'): os.makedirs('data')\n",
    "        # End of episode reached\n",
    "        # Requirement: Do not show report to user.\n",
    "        pass\n",
    "\n",
    "def on_next(b):\n",
    "    global current_recs\n",
    "    \n",
    "    feedback_label.value = \"\"\n",
    "    # info contains recommendations for the *next* step already\n",
    "    if current_step_info:\n",
    "        current_recs = current_step_info['recommendations']\n",
    "        update_ui(current_recs)\n",
    "        \n",
    "    if current_step_info and current_step_info['new_episode']:\n",
    "        feedback_label.value = \"<b>New Episode Started!</b>\"\n",
    "\n",
    "agent1_btn.on_click(on_choice)\n",
    "agent2_btn.on_click(on_choice)\n",
    "next_btn.on_click(on_next)\n",
    "\n",
    "# --- Layout ---\n",
    "ui = widgets.VBox([\n",
    "    header_html,\n",
    "    instructions,\n",
    "    score_label,\n",
    "    widgets.HBox([agent1_btn, agent2_btn]),\n",
    "    feedback_label,\n",
    "    metrics_label,\n",
    "    next_btn,\n",
    "    widgets.HBox([output_plot, output_table])\n",
    "])\n",
    "\n",
    "# Initialize\n",
    "update_ui(current_recs)\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c8238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210b07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}