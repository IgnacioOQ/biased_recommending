{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c20f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to be ran on Google Colab, and it clones a specific branch of a GitHub repository.\n",
    "!git clone -b main https://github.com/IgnacioOQ/biased_recommending\n",
    "%cd biased_recommending\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "dumping_path = '/content/drive/My Drive/Colab Projects/Data Driven ABMs/Data Sets/ignacio_playground/'\n",
    "print(\"Current Directory:\", dumping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path if not already (for notebook execution)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.simulation import GameSession\n",
    "\n",
    "# --- Game State ---\n",
    "# Note: In Colab, the output_dir should be set to the Drive path if desired, \n",
    "# but for local testing 'data' is fine. Users on Colab can change this arg.\n",
    "game = GameSession(output_dir=\"data\")\n",
    "current_recs = game.start_game()\n",
    "current_step_info = None\n",
    "\n",
    "# History for plotting\n",
    "history_scores = []\n",
    "history_episodes = []\n",
    "cumulative_score = 0\n",
    "\n",
    "# --- UI Elements ---\n",
    "output_plot = widgets.Output()\n",
    "\n",
    "header_html = widgets.HTML(value=\"<h1>Recommender Game</h1>\")\n",
    "instructions = widgets.HTML(value=\"\"\"\n",
    "<p><b>Goal:</b> Maximize your score!</p>\n",
    "<p>1. Observe the recommendations from Agent 1 and Agent 2.</p>\n",
    "<p>2. Choose which agent to follow.</p>\n",
    "<p>3. See the outcome (Heads/Tails) and your reward.</p>\n",
    "<hr>\n",
    "\"\"\")\n",
    "\n",
    "agent1_btn = widgets.Button(description=\"Follow Agent 1\", button_style='info')\n",
    "agent2_btn = widgets.Button(description=\"Follow Agent 2\", button_style='info')\n",
    "next_btn = widgets.Button(description=\"Next Step\", disabled=True)\n",
    "\n",
    "score_label = widgets.Label(value=\"Score: 0 | Episode: 0 | Step: 0\")\n",
    "feedback_label = widgets.HTML(value=\"\")\n",
    "metrics_label = widgets.HTML(value=\"\")\n",
    "\n",
    "# --- Logic ---\n",
    "\n",
    "def update_plot():\n",
    "    with output_plot:\n",
    "        clear_output(wait=True)\n",
    "        if not history_scores:\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(history_scores, label=\"Cumulative Score\")\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Performance Over Time\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "def update_ui(recommendations):\n",
    "    rec_text = [\"Recommend\" if r == 1 else \"Not Recommend\" for r in recommendations]\n",
    "    \n",
    "    agent1_btn.description = f\"Agent 1: {rec_text[0]}\"\n",
    "    agent2_btn.description = f\"Agent 2: {rec_text[1]}\"\n",
    "    \n",
    "    agent1_btn.disabled = False\n",
    "    agent2_btn.disabled = False\n",
    "    next_btn.disabled = True\n",
    "    \n",
    "    # Visual cues\n",
    "    agent1_btn.icon = 'thumbs-up' if recommendations[0] == 1 else 'thumbs-down'\n",
    "    agent2_btn.icon = 'thumbs-up' if recommendations[1] == 1 else 'thumbs-down'\n",
    "\n",
    "def on_choice(b):\n",
    "    global cumulative_score, current_step_info\n",
    "    \n",
    "    choice = 0 if b == agent1_btn else 1\n",
    "    \n",
    "    # Process Step\n",
    "    current_step_info = game.process_step(choice)\n",
    "    \n",
    "    # Update Score\n",
    "    reward = current_step_info['human_reward']\n",
    "    cumulative_score += reward\n",
    "    \n",
    "    # Update History\n",
    "    history_scores.append(cumulative_score)\n",
    "    update_plot()\n",
    "    \n",
    "    # Show Feedback\n",
    "    outcome = current_step_info['outcome']\n",
    "    rec_followed = \"Recommend\" if game.current_recommendations[choice] == 1 else \"Not Recommend\"\n",
    "    \n",
    "    res_color = \"green\" if reward > 0 else \"red\"\n",
    "    \n",
    "    feedback_html = f\"\"\"\n",
    "    <div style=\"border: 2px solid {res_color}; padding: 10px; border-radius: 5px;\">\n",
    "        <h3>Outcome: {outcome}</h3>\n",
    "        <p>You followed Agent {choice + 1} ({rec_followed}).</p>\n",
    "        <p><b>Reward: {reward}</b></p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    feedback_label.value = feedback_html\n",
    "    \n",
    "    # Update Status Bar\n",
    "    score_label.value = f\"Score: {cumulative_score} | Episode: {current_step_info['episode_count']} | Step: {game.env.steps}\"\n",
    "    \n",
    "    # Disable choice buttons, enable Next\n",
    "    agent1_btn.disabled = True\n",
    "    agent2_btn.disabled = True\n",
    "    next_btn.disabled = False\n",
    "    \n",
    "    # Check for metrics (End of Episode)\n",
    "    if current_step_info['metrics']:\n",
    "        m = current_step_info['metrics']\n",
    "        # Display Agent 0 metrics as sample\n",
    "        a0 = m['agent_0']\n",
    "        a1 = m['agent_1']\n",
    "        metrics_html = f\"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; padding: 10px; margin-top: 10px;\">\n",
    "            <h4>Episode {current_step_info['episode_count']-1} Analysis</h4>\n",
    "            <p><b>Agent 1 Disagreement with Unbiased:</b> {a0['disagreement_rate']:.2%}</p>\n",
    "            <p><b>Agent 2 Disagreement with Unbiased:</b> {a1['disagreement_rate']:.2%}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        metrics_label.value = metrics_html\n",
    "\n",
    "def on_next(b):\n",
    "    global current_recs\n",
    "    \n",
    "    feedback_label.value = \"\"\n",
    "    # info contains recommendations for the *next* step already\n",
    "    if current_step_info:\n",
    "        current_recs = current_step_info['recommendations']\n",
    "        update_ui(current_recs)\n",
    "        \n",
    "    if current_step_info and current_step_info['new_episode']:\n",
    "        feedback_label.value = \"<b>New Episode Started!</b>\"\n",
    "\n",
    "agent1_btn.on_click(on_choice)\n",
    "agent2_btn.on_click(on_choice)\n",
    "next_btn.on_click(on_next)\n",
    "\n",
    "# --- Layout ---\n",
    "ui = widgets.VBox([\n",
    "    header_html,\n",
    "    instructions,\n",
    "    score_label,\n",
    "    output_plot,\n",
    "    widgets.HBox([agent1_btn, agent2_btn]),\n",
    "    feedback_label,\n",
    "    metrics_label,\n",
    "    next_btn\n",
    "])\n",
    "\n",
    "# Initialize\n",
    "update_ui(current_recs)\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c8238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210b07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
